{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.386722Z",
     "start_time": "2024-12-18T02:21:02.346764Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from config.Experiment_Config import ExperimentConfig\n",
    "from exp.trainer import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de83d11d69e94a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.456823Z",
     "start_time": "2024-12-18T02:21:05.455037Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ExperimentConfig.get_default_config()\n",
    "config.tokenizer_settings.max_length = 512\n",
    "config.training_settings.batch_size = 32\n",
    "config.data_settings.imbalanced_strategy = 'weighted_sampler'\n",
    "config.data_settings.weighted_sampler_alpha = 0.5\n",
    "config.model_settings.weight_init = 'kaiming_normal'\n",
    "config.model_settings.init_hidden_dim = 384\n",
    "config.model_settings.activation = 'gelu'\n",
    "config.model_settings.fine_tune_embedding = False\n",
    "config.training_settings.early_stopping_patience = 20\n",
    "config.training_settings.gradient_clip = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e548caf5142ff5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:12.313680Z",
     "start_time": "2024-12-17T19:32:22.655999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created all necessary directories\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "==================================================\n",
      "\n",
      "📊 Experiment Name: BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\n",
      "📁 Model Directory: saved_models\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\n",
      "📈 Results Directory: results\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\n",
      "\n",
      "🔧 Model Configuration:\n",
      "- Model Type: BiLSTM\n",
      "- Embedding Type: BERT_base_uncased\n",
      "- Hidden Dimensions: [256, 128]\n",
      "- Bidirectional: True\n",
      "- Dropout Rate: 0.1\n",
      "- Attention: False\n",
      "- Fine-tune Embedding: False\n",
      "- Weight Init: kaiming_normal\n",
      "- Activation: gelu\n",
      "\n",
      "⚙️ Training Configuration:\n",
      "- Batch Size: 32\n",
      "- Max Length: 512\n",
      "- Learning Rate: 0.001\n",
      "- Weight Decay: 0.01\n",
      "- Num Epochs: 100\n",
      "- Loss Function: cross_entropy\n",
      "- Optimizer: adam\n",
      "- Early Stopping Patience: 20\n",
      "- Scheduler Patience: 3\n",
      "- Scheduler Factor: 0.1\n",
      "- Min Learning Rate: 1e-06\n",
      "- Checkpoint Frequency: 10\n",
      "\n",
      "📊 Data Configuration:\n",
      "- Imbalanced Strategy: weighted_sampler\n",
      "  • Alpha: 0.5\n",
      "- Number of Classes: 38\n",
      "\n",
      "📂 Directory Configuration:\n",
      "- Model Save Dir: saved_models\n",
      "- Results Save Dir: results\n",
      "\n",
      "💻 Hardware Configuration:\n",
      "- Device: cuda\n",
      "- MPS available: False\n",
      "- CUDA available: True\n",
      "- CUDA devices: 1\n",
      "\n",
      "📚 Dataset Information:\n",
      "- Training samples: 4079\n",
      "- Validation samples: 511\n",
      "- Test samples: 510\n",
      "- Number of batches (train): 127\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "🚀 Starting training...\n",
      "\n",
      "==================================================\n",
      "⏳ Epoch 1/100\n",
      "==================================================\n",
      "\n",
      "┌─────────────────────────────────────┐\n",
      "│ ⏱️  Time Statistics:                │\n",
      "├─────────────────────────────────────┤\n",
      "│  • Current Epoch: 00:00:00       │\n",
      "│  • Average Time:  00:00:00       │\n",
      "│  • Remaining:     00:00:00       │\n",
      "└─────────────────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/127 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Training: 100%|██████████| 127/127 [01:18<00:00,  1.61it/s]\n",
      "c:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Evaluating (val): 100%|██████████| 15/15 [00:14<00:00,  1.06it/s]\n",
      "c:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Results:\n",
      "\n",
      "Training Metrics:\n",
      "accuracy: 0.1257\n",
      "precision_macro: 0.0043\n",
      "precision_micro: 0.1257\n",
      "recall_macro: 0.0259\n",
      "recall_micro: 0.1257\n",
      "f1_macro: 0.0064\n",
      "f1_micro: 0.1257\n",
      "loss: 3.5690\n",
      "\n",
      "Validation Metrics:\n",
      "accuracy: 0.4958\n",
      "precision_macro: 0.0130\n",
      "precision_micro: 0.4958\n",
      "recall_macro: 0.0263\n",
      "recall_micro: 0.4958\n",
      "f1_macro: 0.0174\n",
      "f1_micro: 0.4958\n",
      "loss: 3.2138\n",
      "❌ Error saving confusion matrix\n",
      "Attempted path: results\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\\figures\\latest\\train_confusion_matrix_BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse.png\n",
      "Error details: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yunkai\\\\OneDrive\\\\Program\\\\Py\\\\project\\\\Multi_turn\\\\results\\\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\\\\figures\\\\latest\\\\train_confusion_matrix_BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse.png'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\yunkai\\\\OneDrive\\\\Program\\\\Py\\\\project\\\\Multi_turn\\\\results\\\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\\\\figures\\\\latest\\\\train_confusion_matrix_BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      2\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m metrics_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\OneDrive\\Program\\Py\\project\\Multi_turn\\exp\\trainer.py:768\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;66;03m# Save latest plots for both training and validation\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_confusion_matrix(\n\u001b[0;32m    766\u001b[0m     train_labels, train_preds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_confusion_matrix(\n\u001b[1;32m--> 768\u001b[0m     val_labels, val_preds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_class_performance(\n\u001b[0;32m    770\u001b[0m     train_labels, train_preds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_class_performance(\n\u001b[0;32m    772\u001b[0m     val_labels, val_preds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\OneDrive\\Program\\Py\\project\\Multi_turn\\exp\\trainer.py:385\u001b[0m, in \u001b[0;36mTrainer.plot_confusion_matrix\u001b[1;34m(self, y_true, y_pred, epoch, prefix)\u001b[0m\n\u001b[0;32m    382\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(save_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;66;03m# Save figure\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Saved confusion matrix to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\pyplot.py:1228\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m   1226\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[1;32m-> 1228\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\figure.py:3395\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3393\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3394\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[1;32m-> 3395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2201\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2202\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2204\u001b[0m         result \u001b[38;5;241m=\u001b[39m print_method(\n\u001b[0;32m   2205\u001b[0m             filename,\n\u001b[0;32m   2206\u001b[0m             facecolor\u001b[38;5;241m=\u001b[39mfacecolor,\n\u001b[0;32m   2207\u001b[0m             edgecolor\u001b[38;5;241m=\u001b[39medgecolor,\n\u001b[0;32m   2208\u001b[0m             orientation\u001b[38;5;241m=\u001b[39morientation,\n\u001b[0;32m   2209\u001b[0m             bbox_inches_restore\u001b[38;5;241m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2210\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2211\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2055\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:496\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    444\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 445\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\matplotlib\\image.py:1676\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1674\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1675\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1676\u001b[0m image\u001b[38;5;241m.\u001b[39msave(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\PIL\\Image.py:2600\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2598\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2599\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2600\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2602\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\yunkai\\\\OneDrive\\\\Program\\\\Py\\\\project\\\\Multi_turn\\\\results\\\\BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse\\\\figures\\\\latest\\\\train_confusion_matrix_BiLSTM_BERT_base_uncased_512_2_cross_entropy_kaiming_normal_weighted_sampler_AFalse.png'"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "metrics_history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
