{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.386722Z",
     "start_time": "2024-12-18T02:21:02.346764Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from config.Experiment_Config import ExperimentConfig\n",
    "from exp.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de83d11d69e94a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.456823Z",
     "start_time": "2024-12-18T02:21:05.455037Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ExperimentConfig.get_default_config()\n",
    "config.model_settings.embedding_type = 'XLM_roberta_large'\n",
    "config.training_settings.num_epochs = 1000\n",
    "config.training_settings.batch_size = 32\n",
    "config.tokenizer_settings.max_length = 256\n",
    "config.model_settings.weight_init = 'kaiming_normal'\n",
    "config.data_settings.imbalanced_strategy = 'weighted_sampler'\n",
    "config.data_settings.alpha = 0.1\n",
    "config.model_settings.activation = 'gelu'\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.training_settings.early_stopping_patience = 100\n",
    "config.training_settings.task_type = 'Multi'\n",
    "config.model_settings.num_layers = 12\n",
    "config.model_settings.custom_hidden_dims = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
    "config.model_settings.use_res_net = True\n",
    "config.model_settings.use_attention = False\n",
    "config.training_settings.gradient_clip = 1.0\n",
    "config.training_settings.continue_training = True\n",
    "config.training_settings.learning_rate = 2e-5\n",
    "config.model_settings.fine_tune_lr = 5e-5\n",
    "config.model_settings.use_layer_norm = True\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.model_settings.attention_temperature = 1.0\n",
    "config.model_settings.attention_positions = ['embedding', 'inter_lstm']\n",
    "config.model_settings.use_attention = True\n",
    "config.model_settings.fine_tune_loading_strategies = ['periodic', 'plateau', 'ensemble', 'adaptive']\n",
    "config.model_settings.fine_tune_mode = 'gradual'\n",
    "config.model_settings.num_frozen_layers = 12\n",
    "config.model_settings.fine_tune_reload_freq = 20\n",
    "config.model_settings.dropout_rate = 0.2\n",
    "config.model_settings.gradual_unfreeze_epochs = 50\n",
    "config.model_settings.bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e548caf5142ff5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:12.313680Z",
     "start_time": "2024-12-17T19:32:22.655999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "ğŸ”„ Adaptive periodic reload triggered at epoch 0 (freq=20)\n",
      "âœ… Loaded best fine-tuned embedding model\n",
      "âš ï¸ No ensemble weights available, loaded best weights\n",
      "\n",
      "Grouping parameters...\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.query.weight\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.query.bias\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.key.weight\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.key.bias\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.value.weight\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.value.bias\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.dense.weight\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.dense.bias\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "  â†’ Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.intermediate.dense.weight\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.intermediate.dense.bias\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.dense.weight\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.dense.bias\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.LayerNorm.weight\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.LayerNorm.bias\n",
      "  â†’ Embedding parameter\n",
      "Processing parameter: lstm.0.weight_ih_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.weight_hh_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.bias_ih_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.bias_hh_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.weight_ih_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.weight_hh_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.bias_ih_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.0.bias_hh_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.weight_ih_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.weight_hh_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.bias_ih_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.bias_hh_l0\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.weight_ih_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.weight_hh_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.bias_ih_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: lstm.1.bias_hh_l0_reverse\n",
      "  â†’ Other parameter\n",
      "Processing parameter: res_projections.0.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: res_projections.0.bias\n",
      "  â†’ Other parameter\n",
      "Processing parameter: res_projections.1.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: res_projections.1.bias\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.lstm_0.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.lstm_0.bias\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.lstm_1.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.lstm_1.bias\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.final.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: layer_norms.final.bias\n",
      "  â†’ Other parameter\n",
      "Processing parameter: fc_layers.1.weight\n",
      "  â†’ Other parameter\n",
      "Processing parameter: fc_layers.1.bias\n",
      "  â†’ Other parameter\n",
      "\n",
      "Embedding parameters: 6\n",
      "Attention parameters: 10\n",
      "Other parameters: 28\n",
      "\n",
      "Total parameter groups: 3\n",
      "\n",
      "Optimizer parameter groups:\n",
      "Group 0: 6 parameters, lr=5e-05\n",
      "Group 1: 10 parameters, lr=0.0001\n",
      "Group 2: 28 parameters, lr=0.001\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Experiment Name: BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "ğŸ“ Model Directory: saved_models\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "ğŸ“ˆ Results Directory: results\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "\n",
      "ğŸ”§ Model Configuration:\n",
      "- Model Type: BiLSTM\n",
      "- Embedding Type: XLM_roberta_large\n",
      "- Architecture:\n",
      "  â€¢ Hidden Dimensions: [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
      "  â€¢ Number of Layers: 12\n",
      "  â€¢ Bidirectional: True\n",
      "  â€¢ Dropout Rate: 0.2\n",
      "\n",
      "ğŸ¯ Attention Configuration:\n",
      "- Use Attention: True\n",
      "  â€¢ Number of Heads: 8\n",
      "  â€¢ Attention Positions: ['embedding', 'inter_lstm']\n",
      "  â€¢ Attention Dropout: 0.1\n",
      "  â€¢ Temperature: 1.0\n",
      "\n",
      "ğŸ—ï¸ Architecture Features:\n",
      "- Residual Connections: True\n",
      "  â€¢ Residual Dropout: 0.1\n",
      "- Layer Normalization: True\n",
      "  â€¢ Layer Norm Epsilon: 1e-05\n",
      "  â€¢ Elementwise: False\n",
      "  â€¢ Affine Transform: True\n",
      "\n",
      "ğŸ”„ Fine-tuning Configuration:\n",
      "- Fine-tune Embedding: True\n",
      "  â€¢ Mode: gradual\n",
      "  â€¢ Learning Rate: 5e-05\n",
      "  â€¢ Loading Strategies: ['periodic', 'plateau', 'ensemble', 'adaptive']\n",
      "  â€¢ Reload Frequency: 20\n",
      "  â€¢ Plateau Patience: 5\n",
      "  â€¢ Plateau Threshold: 0.01\n",
      "  â€¢ LR Decay Factor: 0.95\n",
      "\n",
      "âš™ï¸ Training Configuration:\n",
      "- Batch Size: 32\n",
      "- Max Length: 256\n",
      "- Learning Rate: 2e-05\n",
      "- Weight Decay: 0.01\n",
      "- Num Epochs: 1000\n",
      "- Loss Function: cross_entropy\n",
      "- Optimizer: adamw\n",
      "- Gradient Clipping: 1.0\n",
      "\n",
      "ğŸ“ˆ Training Control:\n",
      "- Early Stopping Patience: 100\n",
      "- Scheduler Patience: 3\n",
      "- Scheduler Factor: 0.1\n",
      "- Min Learning Rate: 1e-06\n",
      "- Checkpoint Frequency: 10\n",
      "\n",
      "ğŸ“Š Data Configuration:\n",
      "- Task Type: Multi\n",
      "- Imbalanced Strategy: weighted_sampler\n",
      "  â€¢ Alpha: 1.0\n",
      "- Number of Classes: 38\n",
      "\n",
      "ğŸ“š Dataset Information:\n",
      "- Training samples: 4079\n",
      "- Validation samples: 511\n",
      "- Test samples: 510\n",
      "- Number of batches (train): 127\n",
      "\n",
      "ğŸ’» Hardware Configuration:\n",
      "- Device: cuda\n",
      "- MPS available: False\n",
      "- CUDA available: True\n",
      "- CUDA devices: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Found model in latest folder from epoch 2\n",
      "âœ… Using latest model from epoch 2\n",
      "ğŸ“‚ Loading checkpoint from: saved_models\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\\latest\\model_latest.pt\n",
      "âœ… Successfully loaded corresponding fine-tuned embedding from: fine_tuned_models\\Multi\\question\\XLM_roberta_large\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\\latest\\embedding_model_latest.pt\n",
      "âœ… Successfully loaded checkpoint from epoch 2\n",
      "âœ… Resuming training from epoch 3\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 3/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 3:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 5.00e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/127 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Training:   1%|          | 1/127 [00:00<00:53,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 3):\n",
      "âš ï¸ Vanishing gradient in embedding_model.encoder.layer.11.attention.self.key.bias: 0.0000\n",
      "LSTM - Mean Grad: 1.39e-04, Max Norm: 1.02e-01\n",
      "FC - Mean Grad: 7.63e-04, Max Norm: 1.72e-01\n",
      "ATTENTION - Mean Grad: 5.83e-04, Max Norm: 3.97e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7982, Std: 1.0071\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0801\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0801\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:42<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 3)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.0603       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0153       â”‚ F1 Micro     â”‚ 0.0603       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0176       â”‚ Prec Micro   â”‚ 0.0603       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.0615       â”‚ Recall Micro â”‚ 0.0603       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 3)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.1542       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0272       â”‚ F1 Micro     â”‚ 0.1542       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0318       â”‚ Prec Micro   â”‚ 0.1542       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.0621       â”‚ Recall Micro â”‚ 0.1542       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 3\n",
      "ğŸ’¾ Saved latest validation plots for epoch 3\n",
      "ğŸ’¾ Saved latest metrics at epoch 3\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 3\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 1)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 2:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 3\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 4/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 4:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:23,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 4):\n",
      "LSTM - Mean Grad: 1.03e-04, Max Norm: 1.18e-01\n",
      "FC - Mean Grad: 5.58e-04, Max Norm: 1.10e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7988, Std: 1.0073\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0773\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0773\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:54<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 4)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.0810       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0171       â”‚ F1 Micro     â”‚ 0.0810       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0098       â”‚ Prec Micro   â”‚ 0.0810       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.0780       â”‚ Recall Micro â”‚ 0.0810       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 4)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.4167       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0341       â”‚ F1 Micro     â”‚ 0.4167       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0306       â”‚ Prec Micro   â”‚ 0.4167       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.0935       â”‚ Recall Micro â”‚ 0.4167       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 4\n",
      "ğŸ’¾ Saved latest validation plots for epoch 4\n",
      "ğŸ’¾ Saved latest metrics at epoch 4\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 4\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 2)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 3:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 4\n",
      "ğŸ† Saved best model at epoch 4\n",
      "ğŸ† Saved best training plots for epoch 4\n",
      "ğŸ† Saved best validation plots for epoch 4\n",
      "ğŸ† Saved best metrics at epoch 4\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 4\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 5/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 5:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 2.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|â–         | 2/127 [00:00<00:26,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 5):\n",
      "LSTM - Mean Grad: 1.36e-04, Max Norm: 1.94e-01\n",
      "FC - Mean Grad: 6.00e-04, Max Norm: 1.33e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7929, Std: 1.0082\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0933\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0933\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:25<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 5)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.1235       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0378       â”‚ F1 Micro     â”‚ 0.1235       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0332       â”‚ Prec Micro   â”‚ 0.1235       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1148       â”‚ Recall Micro â”‚ 0.1235       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 5)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.4646       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0536       â”‚ F1 Micro     â”‚ 0.4646       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0442       â”‚ Prec Micro   â”‚ 0.4646       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1181       â”‚ Recall Micro â”‚ 0.4646       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 5\n",
      "ğŸ’¾ Saved latest validation plots for epoch 5\n",
      "ğŸ’¾ Saved latest metrics at epoch 5\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 5\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 4:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 5\n",
      "ğŸ† Saved best model at epoch 5\n",
      "ğŸ† Saved best training plots for epoch 5\n",
      "ğŸ† Saved best validation plots for epoch 5\n",
      "ğŸ† Saved best metrics at epoch 5\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 5\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 6/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 6:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.20e-06\n",
      "  other: 3.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:04,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 6):\n",
      "LSTM - Mean Grad: 2.52e-04, Max Norm: 3.58e-01\n",
      "FC - Mean Grad: 1.03e-03, Max Norm: 2.06e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7967, Std: 1.0067\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0856\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0856\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:39<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 6)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.1683       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0723       â”‚ F1 Micro     â”‚ 0.1683       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0571       â”‚ Prec Micro   â”‚ 0.1683       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1726       â”‚ Recall Micro â”‚ 0.1683       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 6)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.4875       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0766       â”‚ F1 Micro     â”‚ 0.4875       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0593       â”‚ Prec Micro   â”‚ 0.4875       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1744       â”‚ Recall Micro â”‚ 0.4875       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 6\n",
      "ğŸ’¾ Saved latest validation plots for epoch 6\n",
      "ğŸ’¾ Saved latest metrics at epoch 6\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 6\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 5:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 6\n",
      "ğŸ† Saved best model at epoch 6\n",
      "ğŸ† Saved best training plots for epoch 6\n",
      "ğŸ† Saved best validation plots for epoch 6\n",
      "ğŸ† Saved best metrics at epoch 6\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 6\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 7/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 7:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.60e-06\n",
      "  other: 4.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:16,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 7):\n",
      "LSTM - Mean Grad: 3.86e-04, Max Norm: 1.18e+00\n",
      "FC - Mean Grad: 1.25e-03, Max Norm: 2.25e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.8009, Std: 1.0059\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0878\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0878\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:54<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 7)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.2146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0991       â”‚ F1 Micro     â”‚ 0.2146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0876       â”‚ Prec Micro   â”‚ 0.2146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2105       â”‚ Recall Micro â”‚ 0.2146       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 7)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.5042       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1136       â”‚ F1 Micro     â”‚ 0.5042       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0946       â”‚ Prec Micro   â”‚ 0.5042       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2081       â”‚ Recall Micro â”‚ 0.5042       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 7\n",
      "ğŸ’¾ Saved latest validation plots for epoch 7\n",
      "ğŸ’¾ Saved latest metrics at epoch 7\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 7\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 6:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 7\n",
      "ğŸ† Saved best model at epoch 7\n",
      "ğŸ† Saved best training plots for epoch 7\n",
      "ğŸ† Saved best validation plots for epoch 7\n",
      "ğŸ† Saved best metrics at epoch 7\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 7\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 8/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 8:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.00e-06\n",
      "  other: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:13,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 8):\n",
      "LSTM - Mean Grad: 1.31e-04, Max Norm: 2.07e-01\n",
      "FC - Mean Grad: 5.38e-04, Max Norm: 9.14e-02\n",
      "Activations first_layer:\n",
      "  Mean: 0.7919, Std: 1.0064\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1073\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1073\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:53<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 8)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.2431       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1390       â”‚ F1 Micro     â”‚ 0.2431       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1495       â”‚ Prec Micro   â”‚ 0.2431       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2453       â”‚ Recall Micro â”‚ 0.2431       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 8)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.5563       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1461       â”‚ F1 Micro     â”‚ 0.5563       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1403       â”‚ Prec Micro   â”‚ 0.5563       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2347       â”‚ Recall Micro â”‚ 0.5563       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 8\n",
      "ğŸ’¾ Saved latest validation plots for epoch 8\n",
      "ğŸ’¾ Saved latest metrics at epoch 8\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 8\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 7:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 8\n",
      "ğŸ† Saved best model at epoch 8\n",
      "ğŸ† Saved best training plots for epoch 8\n",
      "ğŸ† Saved best validation plots for epoch 8\n",
      "ğŸ† Saved best metrics at epoch 8\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 8\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 9/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 9:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.40e-06\n",
      "  other: 6.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:01,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 9):\n",
      "LSTM - Mean Grad: 3.18e-04, Max Norm: 4.83e-01\n",
      "FC - Mean Grad: 1.49e-03, Max Norm: 2.26e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7872, Std: 1.0085\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0920\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0920\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:25<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 9)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.3113       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.2016       â”‚ F1 Micro     â”‚ 0.3113       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1867       â”‚ Prec Micro   â”‚ 0.3113       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.3042       â”‚ Recall Micro â”‚ 0.3113       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 9)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.5792       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1777       â”‚ F1 Micro     â”‚ 0.5792       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1462       â”‚ Prec Micro   â”‚ 0.5792       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2771       â”‚ Recall Micro â”‚ 0.5792       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 9\n",
      "ğŸ’¾ Saved latest validation plots for epoch 9\n",
      "ğŸ’¾ Saved latest metrics at epoch 9\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 9\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 8:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 9\n",
      "ğŸ† Saved best model at epoch 9\n",
      "ğŸ† Saved best training plots for epoch 9\n",
      "ğŸ† Saved best validation plots for epoch 9\n",
      "ğŸ† Saved best metrics at epoch 9\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 9\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 10/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 10:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.80e-06\n",
      "  other: 7.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<00:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 10):\n",
      "LSTM - Mean Grad: 2.36e-04, Max Norm: 3.91e-01\n",
      "FC - Mean Grad: 1.02e-03, Max Norm: 1.60e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7843, Std: 1.0113\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1176\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1176\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:48<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 10)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.3558       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.2570       â”‚ F1 Micro     â”‚ 0.3558       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.2097       â”‚ Prec Micro   â”‚ 0.3558       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.3567       â”‚ Recall Micro â”‚ 0.3558       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 10)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.5979       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.2273       â”‚ F1 Micro     â”‚ 0.5979       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.2154       â”‚ Prec Micro   â”‚ 0.5979       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.3392       â”‚ Recall Micro â”‚ 0.5979       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 10\n",
      "ğŸ’¾ Saved latest validation plots for epoch 10\n",
      "ğŸ’¾ Saved latest metrics at epoch 10\n",
      "ğŸ“ Saved checkpoint fine-tuned embedding at epoch 10\n",
      "ğŸ“¦ Added checkpoint to ensemble (total: 3)\n",
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "ğŸ”„ Gradual unfreezing at epoch 9:\n",
      "  â€¢ Total layers to unfreeze: 0\n",
      "  â€¢ Layers being unfrozen: []\n",
      "ğŸ“Š Currently unfrozen layers: []\n",
      "ğŸ’¾ Saved latest model at epoch 10\n",
      "ğŸ† Saved best model at epoch 10\n",
      "ğŸ“ Saved checkpoint model at epoch 10\n",
      "ğŸ“ Saved checkpoint metrics at epoch 10\n",
      "ğŸ† Saved best training plots for epoch 10\n",
      "ğŸ† Saved best validation plots for epoch 10\n",
      "ğŸ† Saved best metrics at epoch 10\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 10\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 11/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "Learning rates at epoch 11:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 3.20e-06\n",
      "  other: 8.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:24,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 11):\n",
      "LSTM - Mean Grad: 2.69e-04, Max Norm: 3.41e-01\n",
      "FC - Mean Grad: 1.04e-03, Max Norm: 2.06e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7881, Std: 1.0145\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1201\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1201\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:54<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 11)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.3964       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.2885       â”‚ F1 Micro     â”‚ 0.3964       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.2385       â”‚ Prec Micro   â”‚ 0.3964       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.3904       â”‚ Recall Micro â”‚ 0.3964       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 11)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.5833       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.2292       â”‚ F1 Micro     â”‚ 0.5833       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.2069       â”‚ Prec Micro   â”‚ 0.5833       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.3285       â”‚ Recall Micro â”‚ 0.5833       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 11\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "metrics_history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi_turn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
