{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.386722Z",
     "start_time": "2024-12-18T02:21:02.346764Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from config.Experiment_Config import ExperimentConfig\n",
    "from exp.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de83d11d69e94a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.456823Z",
     "start_time": "2024-12-18T02:21:05.455037Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ExperimentConfig.get_default_config()\n",
    "config.model_settings.embedding_type = 'XLM_roberta_large'\n",
    "config.training_settings.num_epochs = 1000\n",
    "config.training_settings.batch_size = 32\n",
    "config.tokenizer_settings.max_length = 256\n",
    "config.model_settings.weight_init = 'kaiming_normal'\n",
    "config.data_settings.imbalanced_strategy = 'weighted_sampler'\n",
    "config.data_settings.alpha = 0.1\n",
    "config.model_settings.activation = 'gelu'\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.training_settings.early_stopping_patience = 100\n",
    "config.training_settings.task_type = 'Multi'\n",
    "config.model_settings.num_layers = 12\n",
    "config.model_settings.custom_hidden_dims = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
    "config.model_settings.use_res_net = True\n",
    "config.model_settings.use_attention = False\n",
    "config.training_settings.gradient_clip = 1.0\n",
    "config.training_settings.continue_training = True\n",
    "config.training_settings.learning_rate = 2e-5\n",
    "config.model_settings.fine_tune_lr = 5e-5\n",
    "config.model_settings.use_layer_norm = True\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.model_settings.attention_temperature = 1.0\n",
    "config.model_settings.attention_positions = ['embedding', 'inter_lstm']\n",
    "config.model_settings.use_attention = True\n",
    "config.model_settings.fine_tune_loading_strategies = ['periodic', 'plateau']\n",
    "config.model_settings.fine_tune_mode = 'gradual'\n",
    "config.model_settings.num_frozen_layers = 12\n",
    "config.model_settings.fine_tune_reload_freq = 20\n",
    "config.model_settings.dropout_rate = 0.2\n",
    "config.model_settings.gradual_unfreeze_epochs = 50\n",
    "config.model_settings.bidirectional = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548caf5142ff5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:12.313680Z",
     "start_time": "2024-12-17T19:32:22.655999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Gradual fine-tuning initialized (starting with last layer)\n",
      "ğŸ“Š Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "ğŸ”„ Periodic reload triggered at epoch 0\n",
      "âœ… Loaded best model weights\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Experiment Name: BL_XL_L12H256M256_W2e-5FT5e-5CE-GeLU_WS_ATN-EI_LD-PL20_ARNTG\n",
      "ğŸ“ Model Directory: saved_models\\Multi\\question\\BL_XL_L12H256M256_W2e-5FT5e-5CE-GeLU_WS_ATN-EI_LD-PL20_ARNTG\n",
      "ğŸ“ˆ Results Directory: results\\Multi\\question\\BL_XL_L12H256M256_W2e-5FT5e-5CE-GeLU_WS_ATN-EI_LD-PL20_ARNTG\n",
      "\n",
      "ğŸ”§ Model Configuration:\n",
      "- Model Type: BiLSTM\n",
      "- Embedding Type: XLM_roberta_large\n",
      "- Architecture:\n",
      "  â€¢ Hidden Dimensions: [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
      "  â€¢ Number of Layers: 12\n",
      "  â€¢ Bidirectional: True\n",
      "  â€¢ Dropout Rate: 0.2\n",
      "\n",
      "ğŸ¯ Attention Configuration:\n",
      "- Use Attention: True\n",
      "  â€¢ Number of Heads: 8\n",
      "  â€¢ Attention Positions: ['embedding', 'inter_lstm']\n",
      "  â€¢ Attention Dropout: 0.1\n",
      "  â€¢ Temperature: 1.0\n",
      "\n",
      "ğŸ—ï¸ Architecture Features:\n",
      "- Residual Connections: True\n",
      "  â€¢ Residual Dropout: 0.1\n",
      "- Layer Normalization: True\n",
      "  â€¢ Layer Norm Epsilon: 1e-05\n",
      "  â€¢ Elementwise: False\n",
      "  â€¢ Affine Transform: True\n",
      "\n",
      "ğŸ”„ Fine-tuning Configuration:\n",
      "- Fine-tune Embedding: True\n",
      "  â€¢ Mode: gradual\n",
      "  â€¢ Learning Rate: 5e-05\n",
      "  â€¢ Loading Strategies: ['periodic', 'plateau']\n",
      "  â€¢ Reload Frequency: 20\n",
      "  â€¢ Plateau Patience: 5\n",
      "  â€¢ Plateau Threshold: 0.0001\n",
      "  â€¢ LR Decay Factor: 0.95\n",
      "\n",
      "âš™ï¸ Training Configuration:\n",
      "- Batch Size: 32\n",
      "- Max Length: 256\n",
      "- Learning Rate: 2e-05\n",
      "- Weight Decay: 0.01\n",
      "- Num Epochs: 1000\n",
      "- Loss Function: cross_entropy\n",
      "- Optimizer: adamw\n",
      "- Gradient Clipping: 1.0\n",
      "\n",
      "ğŸ“ˆ Training Control:\n",
      "- Early Stopping Patience: 100\n",
      "- Scheduler Patience: 3\n",
      "- Scheduler Factor: 0.1\n",
      "- Min Learning Rate: 1e-06\n",
      "- Checkpoint Frequency: 10\n",
      "\n",
      "ğŸ“Š Data Configuration:\n",
      "- Task Type: Multi\n",
      "- Imbalanced Strategy: weighted_sampler\n",
      "  â€¢ Alpha: 1.0\n",
      "- Number of Classes: 38\n",
      "\n",
      "ğŸ“š Dataset Information:\n",
      "- Training samples: 4079\n",
      "- Validation samples: 511\n",
      "- Test samples: 510\n",
      "- Number of batches (train): 127\n",
      "\n",
      "ğŸ’» Hardware Configuration:\n",
      "- Device: cuda\n",
      "- MPS available: False\n",
      "- CUDA available: True\n",
      "- CUDA devices: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid checkpoints found, starting fresh training\n",
      "âš ï¸ No checkpoint found, starting training from scratch\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 1/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/127 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Training:   1%|          | 1/127 [00:00<01:44,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 1):\n",
      "âš ï¸ Vanishing gradient in embedding_model.encoder.layer.11.attention.self.key.bias: 0.0000\n",
      "LSTM - Mean Grad: 6.85e-05, Max Norm: 5.40e-02\n",
      "FC - Mean Grad: 3.60e-04, Max Norm: 5.36e-02\n",
      "ATTENTION - Mean Grad: 1.09e-04, Max Norm: 7.71e-02\n",
      "Activations first_layer:\n",
      "  Mean: 0.7749, Std: 1.0001\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0378\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0378\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:27<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 1)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.0551       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0255       â”‚ F1 Micro     â”‚ 0.0551       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0418       â”‚ Prec Micro   â”‚ 0.0551       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.0534       â”‚ Recall Micro â”‚ 0.0551       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âš ï¸ No latest fine-tuned model found for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 1)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.0854       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0461       â”‚ F1 Micro     â”‚ 0.0854       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0667       â”‚ Prec Micro   â”‚ 0.0854       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1099       â”‚ Recall Micro â”‚ 0.0854       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 1\n",
      "ğŸ’¾ Saved latest validation plots for epoch 1\n",
      "ğŸ’¾ Saved latest metrics at epoch 1\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 1\n",
      "ğŸ’¾ Saved latest model at epoch 1\n",
      "ğŸ† Saved best model at epoch 1\n",
      "ğŸ† Saved best training plots for epoch 1\n",
      "ğŸ† Saved best validation plots for epoch 1\n",
      "ğŸ† Saved best metrics at epoch 1\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 1\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 2/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<00:46,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 2):\n",
      "âš ï¸ Vanishing gradient in embedding_model.encoder.layer.11.attention.self.key.bias: 0.0000\n",
      "LSTM - Mean Grad: 2.03e-04, Max Norm: 1.46e-01\n",
      "FC - Mean Grad: 9.19e-04, Max Norm: 1.77e-01\n",
      "ATTENTION - Mean Grad: 3.76e-04, Max Norm: 2.73e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7733, Std: 1.0003\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0718\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0718\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:31<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 2)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.2121       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1117       â”‚ F1 Micro     â”‚ 0.2121       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1406       â”‚ Prec Micro   â”‚ 0.2121       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2147       â”‚ Recall Micro â”‚ 0.2121       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 2)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.2729       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.0797       â”‚ F1 Micro     â”‚ 0.2729       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.0839       â”‚ Prec Micro   â”‚ 0.2729       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1528       â”‚ Recall Micro â”‚ 0.2729       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 2\n",
      "ğŸ’¾ Saved latest validation plots for epoch 2\n",
      "ğŸ’¾ Saved latest metrics at epoch 2\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 2\n",
      "ğŸ’¾ Saved latest model at epoch 2\n",
      "ğŸ† Saved best model at epoch 2\n",
      "ğŸ† Saved best training plots for epoch 2\n",
      "ğŸ† Saved best validation plots for epoch 2\n",
      "ğŸ† Saved best metrics at epoch 2\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 2\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â³ Epoch 3/1000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:06,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Training Dynamics Monitor (Epoch 3):\n",
      "âš ï¸ Vanishing gradient in embedding_model.encoder.layer.11.attention.self.key.bias: 0.0000\n",
      "LSTM - Mean Grad: 1.65e-04, Max Norm: 1.42e-01\n",
      "FC - Mean Grad: 6.01e-04, Max Norm: 1.22e-01\n",
      "ATTENTION - Mean Grad: 2.97e-04, Max Norm: 2.48e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7723, Std: 1.0014\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0893\n",
      "âš ï¸ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0893\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [00:30<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Train Metrics (Epoch 3)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.2790       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1890       â”‚ F1 Micro     â”‚ 0.2790       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.2202       â”‚ Prec Micro   â”‚ 0.2790       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.2828       â”‚ Recall Micro â”‚ 0.2790       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "âœ… Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:02<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Val Metrics (Epoch 3)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â”‚ Accuracy     â”‚ 0.4146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ F1 Macro     â”‚ 0.1067       â”‚ F1 Micro     â”‚ 0.4146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Prec Macro   â”‚ 0.1458       â”‚ Prec Micro   â”‚ 0.4146       â”‚\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â”‚ Recall Macro â”‚ 0.1754       â”‚ Recall Micro â”‚ 0.4146       â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "ğŸ’¾ Saved latest training plots for epoch 3\n",
      "ğŸ’¾ Saved latest validation plots for epoch 3\n",
      "ğŸ’¾ Saved latest metrics at epoch 3\n",
      "ğŸ’¾ Saved latest fine-tuned embedding at epoch 3\n",
      "ğŸ’¾ Saved latest model at epoch 3\n",
      "ğŸ† Saved best model at epoch 3\n",
      "ğŸ† Saved best training plots for epoch 3\n",
      "ğŸ† Saved best validation plots for epoch 3\n",
      "ğŸ† Saved best metrics at epoch 3\n",
      "ğŸ† Saved best fine-tuned embedding at epoch 3\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "metrics_history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi_turn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
