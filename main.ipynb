{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.386722Z",
     "start_time": "2024-12-18T02:21:02.346764Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yunkai\\.conda\\envs\\Multi_turn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from config.Experiment_Config import ExperimentConfig\n",
    "from exp.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de83d11d69e94a7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:05.456823Z",
     "start_time": "2024-12-18T02:21:05.455037Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ExperimentConfig.get_default_config()\n",
    "config.model_settings.embedding_type = 'XLM_roberta_large'\n",
    "config.training_settings.num_epochs = 1000\n",
    "config.training_settings.batch_size = 32\n",
    "config.tokenizer_settings.max_length = 256\n",
    "config.model_settings.weight_init = 'kaiming_normal'\n",
    "config.data_settings.imbalanced_strategy = 'weighted_sampler'\n",
    "config.data_settings.alpha = 0.1\n",
    "config.model_settings.activation = 'gelu'\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.training_settings.early_stopping_patience = 100\n",
    "config.training_settings.task_type = 'Multi'\n",
    "config.model_settings.num_layers = 12\n",
    "config.model_settings.custom_hidden_dims = [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
    "config.model_settings.use_res_net = True\n",
    "config.model_settings.use_attention = False\n",
    "config.training_settings.gradient_clip = 1.0\n",
    "config.training_settings.continue_training = True\n",
    "config.training_settings.learning_rate = 2e-5\n",
    "config.model_settings.fine_tune_lr = 5e-5\n",
    "config.model_settings.use_layer_norm = True\n",
    "config.model_settings.fine_tune_embedding = True\n",
    "config.model_settings.attention_temperature = 1.0\n",
    "config.model_settings.attention_positions = ['embedding', 'inter_lstm']\n",
    "config.model_settings.use_attention = True\n",
    "config.model_settings.fine_tune_loading_strategies = ['periodic', 'plateau', 'ensemble', 'adaptive']\n",
    "config.model_settings.fine_tune_mode = 'gradual'\n",
    "config.model_settings.num_frozen_layers = 12\n",
    "config.model_settings.fine_tune_reload_freq = 20\n",
    "config.model_settings.dropout_rate = 0.2\n",
    "config.model_settings.gradual_unfreeze_epochs = 50\n",
    "config.model_settings.bidirectional = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e548caf5142ff5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T02:21:12.313680Z",
     "start_time": "2024-12-17T19:32:22.655999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1024 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "🔄 Adaptive periodic reload triggered at epoch 0 (freq=20)\n",
      "✅ Loaded best fine-tuned embedding model\n",
      "⚠️ No ensemble weights available, loaded best weights\n",
      "\n",
      "Grouping parameters...\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.query.weight\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.query.bias\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.key.weight\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.key.bias\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.value.weight\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.self.value.bias\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.dense.weight\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.dense.bias\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "  → Attention parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.intermediate.dense.weight\n",
      "  → Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.intermediate.dense.bias\n",
      "  → Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.dense.weight\n",
      "  → Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.dense.bias\n",
      "  → Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.LayerNorm.weight\n",
      "  → Embedding parameter\n",
      "Processing parameter: embedding_model.encoder.layer.11.output.LayerNorm.bias\n",
      "  → Embedding parameter\n",
      "Processing parameter: lstm.0.weight_ih_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.weight_hh_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.bias_ih_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.bias_hh_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.weight_ih_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.weight_hh_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.bias_ih_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.0.bias_hh_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.weight_ih_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.weight_hh_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.bias_ih_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.bias_hh_l0\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.weight_ih_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.weight_hh_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.bias_ih_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: lstm.1.bias_hh_l0_reverse\n",
      "  → Other parameter\n",
      "Processing parameter: res_projections.0.weight\n",
      "  → Other parameter\n",
      "Processing parameter: res_projections.0.bias\n",
      "  → Other parameter\n",
      "Processing parameter: res_projections.1.weight\n",
      "  → Other parameter\n",
      "Processing parameter: res_projections.1.bias\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.lstm_0.weight\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.lstm_0.bias\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.lstm_1.weight\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.lstm_1.bias\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.final.weight\n",
      "  → Other parameter\n",
      "Processing parameter: layer_norms.final.bias\n",
      "  → Other parameter\n",
      "Processing parameter: fc_layers.1.weight\n",
      "  → Other parameter\n",
      "Processing parameter: fc_layers.1.bias\n",
      "  → Other parameter\n",
      "\n",
      "Embedding parameters: 6\n",
      "Attention parameters: 10\n",
      "Other parameters: 28\n",
      "\n",
      "Total parameter groups: 3\n",
      "\n",
      "Optimizer parameter groups:\n",
      "Group 0: 6 parameters, lr=5e-05\n",
      "Group 1: 10 parameters, lr=0.0001\n",
      "Group 2: 28 parameters, lr=0.001\n",
      "\n",
      "==================================================\n",
      "EXPERIMENT CONFIGURATION\n",
      "==================================================\n",
      "\n",
      "📊 Experiment Name: BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "📁 Model Directory: saved_models\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "📈 Results Directory: results\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\n",
      "\n",
      "🔧 Model Configuration:\n",
      "- Model Type: BiLSTM\n",
      "- Embedding Type: XLM_roberta_large\n",
      "- Architecture:\n",
      "  • Hidden Dimensions: [1024, 1024, 512, 512, 256, 256, 128, 128, 64, 64, 64, 64]\n",
      "  • Number of Layers: 12\n",
      "  • Bidirectional: True\n",
      "  • Dropout Rate: 0.2\n",
      "\n",
      "🎯 Attention Configuration:\n",
      "- Use Attention: True\n",
      "  • Number of Heads: 8\n",
      "  • Attention Positions: ['embedding', 'inter_lstm']\n",
      "  • Attention Dropout: 0.1\n",
      "  • Temperature: 1.0\n",
      "\n",
      "🏗️ Architecture Features:\n",
      "- Residual Connections: True\n",
      "  • Residual Dropout: 0.1\n",
      "- Layer Normalization: True\n",
      "  • Layer Norm Epsilon: 1e-05\n",
      "  • Elementwise: False\n",
      "  • Affine Transform: True\n",
      "\n",
      "🔄 Fine-tuning Configuration:\n",
      "- Fine-tune Embedding: True\n",
      "  • Mode: gradual\n",
      "  • Learning Rate: 5e-05\n",
      "  • Loading Strategies: ['periodic', 'plateau', 'ensemble', 'adaptive']\n",
      "  • Reload Frequency: 20\n",
      "  • Plateau Patience: 5\n",
      "  • Plateau Threshold: 0.01\n",
      "  • LR Decay Factor: 0.95\n",
      "\n",
      "⚙️ Training Configuration:\n",
      "- Batch Size: 32\n",
      "- Max Length: 256\n",
      "- Learning Rate: 2e-05\n",
      "- Weight Decay: 0.01\n",
      "- Num Epochs: 1000\n",
      "- Loss Function: cross_entropy\n",
      "- Optimizer: adamw\n",
      "- Gradient Clipping: 1.0\n",
      "\n",
      "📈 Training Control:\n",
      "- Early Stopping Patience: 100\n",
      "- Scheduler Patience: 3\n",
      "- Scheduler Factor: 0.1\n",
      "- Min Learning Rate: 1e-06\n",
      "- Checkpoint Frequency: 10\n",
      "\n",
      "📊 Data Configuration:\n",
      "- Task Type: Multi\n",
      "- Imbalanced Strategy: weighted_sampler\n",
      "  • Alpha: 1.0\n",
      "- Number of Classes: 38\n",
      "\n",
      "📚 Dataset Information:\n",
      "- Training samples: 4079\n",
      "- Validation samples: 511\n",
      "- Test samples: 510\n",
      "- Number of batches (train): 127\n",
      "\n",
      "💻 Hardware Configuration:\n",
      "- Device: cuda\n",
      "- MPS available: False\n",
      "- CUDA available: True\n",
      "- CUDA devices: 1\n",
      "\n",
      "==================================================\n",
      "\n",
      "📝 Found model in latest folder from epoch 2\n",
      "✅ Using latest model from epoch 2\n",
      "📂 Loading checkpoint from: saved_models\\Multi\\question\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\\latest\\model_latest.pt\n",
      "✅ Successfully loaded corresponding fine-tuned embedding from: fine_tuned_models\\Multi\\question\\XLM_roberta_large\\BL_XL_L12H256M256_W2e-5-EL5e-5-WD1e-2CE-GeLU_WS_ATN-EI-1e-6_LD-AEPL-20_a10_p5_e3_ARNTG\\latest\\embedding_model_latest.pt\n",
      "✅ Successfully loaded checkpoint from epoch 2\n",
      "✅ Resuming training from epoch 3\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 3/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 3:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 5.00e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/127 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Training:   1%|          | 1/127 [00:00<00:53,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 3):\n",
      "⚠️ Vanishing gradient in embedding_model.encoder.layer.11.attention.self.key.bias: 0.0000\n",
      "LSTM - Mean Grad: 1.39e-04, Max Norm: 1.02e-01\n",
      "FC - Mean Grad: 7.63e-04, Max Norm: 1.72e-01\n",
      "ATTENTION - Mean Grad: 5.83e-04, Max Norm: 3.97e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7982, Std: 1.0071\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0801\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0801\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:42<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 3)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.0603       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0153       │ F1 Micro     │ 0.0603       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0176       │ Prec Micro   │ 0.0603       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.0615       │ Recall Micro │ 0.0603       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 3)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.1542       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0272       │ F1 Micro     │ 0.1542       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0318       │ Prec Micro   │ 0.1542       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.0621       │ Recall Micro │ 0.1542       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 3\n",
      "💾 Saved latest validation plots for epoch 3\n",
      "💾 Saved latest metrics at epoch 3\n",
      "💾 Saved latest fine-tuned embedding at epoch 3\n",
      "📦 Added checkpoint to ensemble (total: 1)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 2:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 3\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 4/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 4:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 1.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:23,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 4):\n",
      "LSTM - Mean Grad: 1.03e-04, Max Norm: 1.18e-01\n",
      "FC - Mean Grad: 5.58e-04, Max Norm: 1.10e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7988, Std: 1.0073\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0773\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0773\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:54<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 4)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.0810       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0171       │ F1 Micro     │ 0.0810       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0098       │ Prec Micro   │ 0.0810       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.0780       │ Recall Micro │ 0.0810       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 4)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.4167       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0341       │ F1 Micro     │ 0.4167       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0306       │ Prec Micro   │ 0.4167       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.0935       │ Recall Micro │ 0.4167       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 4\n",
      "💾 Saved latest validation plots for epoch 4\n",
      "💾 Saved latest metrics at epoch 4\n",
      "💾 Saved latest fine-tuned embedding at epoch 4\n",
      "📦 Added checkpoint to ensemble (total: 2)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 3:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 4\n",
      "🏆 Saved best model at epoch 4\n",
      "🏆 Saved best training plots for epoch 4\n",
      "🏆 Saved best validation plots for epoch 4\n",
      "🏆 Saved best metrics at epoch 4\n",
      "🏆 Saved best fine-tuned embedding at epoch 4\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 5/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 5:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.00e-06\n",
      "  other: 2.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 2/127 [00:00<00:26,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 5):\n",
      "LSTM - Mean Grad: 1.36e-04, Max Norm: 1.94e-01\n",
      "FC - Mean Grad: 6.00e-04, Max Norm: 1.33e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7929, Std: 1.0082\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0933\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0933\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:25<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 5)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.1235       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0378       │ F1 Micro     │ 0.1235       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0332       │ Prec Micro   │ 0.1235       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.1148       │ Recall Micro │ 0.1235       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:02<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 5)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.4646       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0536       │ F1 Micro     │ 0.4646       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0442       │ Prec Micro   │ 0.4646       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.1181       │ Recall Micro │ 0.4646       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 5\n",
      "💾 Saved latest validation plots for epoch 5\n",
      "💾 Saved latest metrics at epoch 5\n",
      "💾 Saved latest fine-tuned embedding at epoch 5\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 4:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 5\n",
      "🏆 Saved best model at epoch 5\n",
      "🏆 Saved best training plots for epoch 5\n",
      "🏆 Saved best validation plots for epoch 5\n",
      "🏆 Saved best metrics at epoch 5\n",
      "🏆 Saved best fine-tuned embedding at epoch 5\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 6/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 6:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.20e-06\n",
      "  other: 3.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:04,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 6):\n",
      "LSTM - Mean Grad: 2.52e-04, Max Norm: 3.58e-01\n",
      "FC - Mean Grad: 1.03e-03, Max Norm: 2.06e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7967, Std: 1.0067\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0856\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0856\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:39<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 6)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.1683       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0723       │ F1 Micro     │ 0.1683       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0571       │ Prec Micro   │ 0.1683       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.1726       │ Recall Micro │ 0.1683       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:05<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 6)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.4875       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0766       │ F1 Micro     │ 0.4875       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0593       │ Prec Micro   │ 0.4875       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.1744       │ Recall Micro │ 0.4875       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 6\n",
      "💾 Saved latest validation plots for epoch 6\n",
      "💾 Saved latest metrics at epoch 6\n",
      "💾 Saved latest fine-tuned embedding at epoch 6\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 5:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 6\n",
      "🏆 Saved best model at epoch 6\n",
      "🏆 Saved best training plots for epoch 6\n",
      "🏆 Saved best validation plots for epoch 6\n",
      "🏆 Saved best metrics at epoch 6\n",
      "🏆 Saved best fine-tuned embedding at epoch 6\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 7/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 7:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 1.60e-06\n",
      "  other: 4.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:16,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 7):\n",
      "LSTM - Mean Grad: 3.86e-04, Max Norm: 1.18e+00\n",
      "FC - Mean Grad: 1.25e-03, Max Norm: 2.25e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.8009, Std: 1.0059\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0878\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0878\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:54<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 7)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.2146       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.0991       │ F1 Micro     │ 0.2146       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0876       │ Prec Micro   │ 0.2146       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.2105       │ Recall Micro │ 0.2146       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 7)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.5042       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.1136       │ F1 Micro     │ 0.5042       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.0946       │ Prec Micro   │ 0.5042       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.2081       │ Recall Micro │ 0.5042       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 7\n",
      "💾 Saved latest validation plots for epoch 7\n",
      "💾 Saved latest metrics at epoch 7\n",
      "💾 Saved latest fine-tuned embedding at epoch 7\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 6:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 7\n",
      "🏆 Saved best model at epoch 7\n",
      "🏆 Saved best training plots for epoch 7\n",
      "🏆 Saved best validation plots for epoch 7\n",
      "🏆 Saved best metrics at epoch 7\n",
      "🏆 Saved best fine-tuned embedding at epoch 7\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 8/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 8:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.00e-06\n",
      "  other: 5.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:13,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 8):\n",
      "LSTM - Mean Grad: 1.31e-04, Max Norm: 2.07e-01\n",
      "FC - Mean Grad: 5.38e-04, Max Norm: 9.14e-02\n",
      "Activations first_layer:\n",
      "  Mean: 0.7919, Std: 1.0064\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1073\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1073\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:53<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 8)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.2431       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.1390       │ F1 Micro     │ 0.2431       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.1495       │ Prec Micro   │ 0.2431       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.2453       │ Recall Micro │ 0.2431       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:05<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 8)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.5563       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.1461       │ F1 Micro     │ 0.5563       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.1403       │ Prec Micro   │ 0.5563       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.2347       │ Recall Micro │ 0.5563       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 8\n",
      "💾 Saved latest validation plots for epoch 8\n",
      "💾 Saved latest metrics at epoch 8\n",
      "💾 Saved latest fine-tuned embedding at epoch 8\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 7:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 8\n",
      "🏆 Saved best model at epoch 8\n",
      "🏆 Saved best training plots for epoch 8\n",
      "🏆 Saved best validation plots for epoch 8\n",
      "🏆 Saved best metrics at epoch 8\n",
      "🏆 Saved best fine-tuned embedding at epoch 8\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 9/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 9:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.40e-06\n",
      "  other: 6.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:01,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 9):\n",
      "LSTM - Mean Grad: 3.18e-04, Max Norm: 4.83e-01\n",
      "FC - Mean Grad: 1.49e-03, Max Norm: 2.26e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7872, Std: 1.0085\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.0920\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.0920\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:25<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 9)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.3113       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.2016       │ F1 Micro     │ 0.3113       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.1867       │ Prec Micro   │ 0.3113       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.3042       │ Recall Micro │ 0.3113       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:02<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 9)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.5792       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.1777       │ F1 Micro     │ 0.5792       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.1462       │ Prec Micro   │ 0.5792       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.2771       │ Recall Micro │ 0.5792       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 9\n",
      "💾 Saved latest validation plots for epoch 9\n",
      "💾 Saved latest metrics at epoch 9\n",
      "💾 Saved latest fine-tuned embedding at epoch 9\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 8:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 9\n",
      "🏆 Saved best model at epoch 9\n",
      "🏆 Saved best training plots for epoch 9\n",
      "🏆 Saved best validation plots for epoch 9\n",
      "🏆 Saved best metrics at epoch 9\n",
      "🏆 Saved best fine-tuned embedding at epoch 9\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 10/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 10:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 2.80e-06\n",
      "  other: 7.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<00:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 10):\n",
      "LSTM - Mean Grad: 2.36e-04, Max Norm: 3.91e-01\n",
      "FC - Mean Grad: 1.02e-03, Max Norm: 1.60e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7843, Std: 1.0113\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1176\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1176\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:48<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 10)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.3558       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.2570       │ F1 Micro     │ 0.3558       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.2097       │ Prec Micro   │ 0.3558       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.3567       │ Recall Micro │ 0.3558       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 10)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.5979       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.2273       │ F1 Micro     │ 0.5979       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.2154       │ Prec Micro   │ 0.5979       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.3392       │ Recall Micro │ 0.5979       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 10\n",
      "💾 Saved latest validation plots for epoch 10\n",
      "💾 Saved latest metrics at epoch 10\n",
      "📁 Saved checkpoint fine-tuned embedding at epoch 10\n",
      "📦 Added checkpoint to ensemble (total: 3)\n",
      "🔄 Gradual fine-tuning initialized (starting with last layer)\n",
      "📊 Trainable parameters: 7,087,872 / 109,482,240 (6.5%)\n",
      "\n",
      "🔄 Gradual unfreezing at epoch 9:\n",
      "  • Total layers to unfreeze: 0\n",
      "  • Layers being unfrozen: []\n",
      "📊 Currently unfrozen layers: []\n",
      "💾 Saved latest model at epoch 10\n",
      "🏆 Saved best model at epoch 10\n",
      "📁 Saved checkpoint model at epoch 10\n",
      "📁 Saved checkpoint metrics at epoch 10\n",
      "🏆 Saved best training plots for epoch 10\n",
      "🏆 Saved best validation plots for epoch 10\n",
      "🏆 Saved best metrics at epoch 10\n",
      "🏆 Saved best fine-tuned embedding at epoch 10\n",
      "\n",
      "──────────────────────────────────────────────────\n",
      "⏳ Epoch 11/1000\n",
      "──────────────────────────────────────────────────\n",
      "\n",
      "Learning rates at epoch 11:\n",
      "  embedding: 1.00e-06\n",
      "  attention: 3.20e-06\n",
      "  other: 8.00e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/127 [00:00<01:24,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Dynamics Monitor (Epoch 11):\n",
      "LSTM - Mean Grad: 2.69e-04, Max Norm: 3.41e-01\n",
      "FC - Mean Grad: 1.04e-03, Max Norm: 2.06e-01\n",
      "Activations first_layer:\n",
      "  Mean: 0.7881, Std: 1.0145\n",
      "Activations last_layer:\n",
      "  Mean: 0.0263, Std: 0.1201\n",
      "⚠️ Low activation values in last_layer\n",
      "Outputs - Mean: 0.0263, Std: 0.1201\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 127/127 [00:54<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Metrics (Epoch 11)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.3964       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.2885       │ F1 Micro     │ 0.3964       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.2385       │ Prec Micro   │ 0.3964       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.3904       │ Recall Micro │ 0.3964       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "✅ Loaded latest fine-tuned embedding for val evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (val): 100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Val Metrics (Epoch 11)\n",
      "═════════════════════════════════════════════════════════════════\n",
      "│ Accuracy     │ 0.5833       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ F1 Macro     │ 0.2292       │ F1 Micro     │ 0.5833       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Prec Macro   │ 0.2069       │ Prec Micro   │ 0.5833       │\n",
      "─────────────────────────────────────────────────────────────────\n",
      "│ Recall Macro │ 0.3285       │ Recall Micro │ 0.5833       │\n",
      "═════════════════════════════════════════════════════════════════\n",
      "💾 Saved latest training plots for epoch 11\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Train model\n",
    "metrics_history = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi_turn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
